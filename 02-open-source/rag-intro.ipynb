{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gathering context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../01-intro/documents.json\", \"rt\") as f_in:\n",
    "    docs_raw = json.load(f_in)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict[\"documents\"]:\n",
    "        doc[\"course\"] = course_dict[\"course\"]\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"the course has already started, can I still enroll?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ollama phi3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1/\",\n",
    "    api_key=\"ollama\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '7cfb7484ed0b', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'iNrf-i6FQ3CpdzKpXNqwzA', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\"number_of_shards\": 1, \"number_of_replicas\": 0},\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9669bf380144207af04075dd1644525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1015 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\",\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\"term\": {\"course\": \"data-engineering-zoomcamp\"}},\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "\n",
    "    result_docs = []\n",
    "\n",
    "    for hit in response[\"hits\"][\"hits\"]:\n",
    "        result_docs.append(hit[\"_source\"])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = (\n",
    "            context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "        )\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(model=\"phi3\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer, search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"how do I run kafka?\"\n",
    "answer, search_results = rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To run Kafka in a terminal for Java projects like JsonProducer, follow these steps based on Section 6's context:\n",
      "\n",
      "1. Open your project directory using Git and clone it if necessary by watching an online tutorial about cloning from GitHub as suggested in the FAQ database under \"General course-related questions\".\n",
      "\n",
      "2. After ensuring that DuckDB is installed locally, create a virtual environment specific for Kafka operations:\n",
      "```\n",
      "python -m venv env  # This should be executed only once to set up your Python environment and install required packages without affecting other projects' dependencies on the system-wide Python installation. Use 'source env/bin/activate'. On Windows, replace it with '.env\\Scripts\\activate', where `.env` is a directory containing an `environment.yml`.\n",
      "pip install -r ../requirements.txt  # Assuming your requirements file includes DuckDB and any Kafka-related packages listed afterward (e.g., kafkastream). It's vital to include both the Java code path in 'src/main/' as well, for example: src/main/java/org/example/JsonProducer\n",
      "```\n",
      "3. Now that your environment is ready with DuckDB and Kafka-related packages installed, run JsonProducer or similar producers directly using Java from within this activated virtual environment to interact with the local Kafka setup for streaming data as mentioned in Section 6: \"Module 6: Streaming With Kafka\".\n",
      "4. It's also important not to forget that passwords and keys must never be stored inside a Git repository, even private ones; use `.gitignore` appropriately before pushing your code changes with `git`. Additional resources for better understanding are available at the provided links in Section 6: \"Module 6: Streaming With Kafka\".\n",
      "5. For checking compatibility between local and container Spark versions when working on projects involving streaming data, ensure that you first run a Docker image of the intended environment as hinted towards the end of context from Module 6 before attempting to match SPARK_VERSION in `build.sh`. This helps guarantee consistent runtime environments across different platforms (MacOS, Linux or Windows).\n",
      "\n",
      "Please note: The specific commands may differ based on your operating system and local setup details provided by \"Module 6: Streaming With Kafka\". Refer back to the FAQ database as necessary for more detailed guidance.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I just disovered the course. Can I still join it?\"\n",
    "answer, search_results = rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Yes, you can still join the course even if you discover it later or have already joined but are late in doing so. As long as there's time left for submitting homeworks and no final projects need immediate attention (since deadlines might apply), joining is possible. Just remember to submit your work on time!\n",
      "\n",
      "It seems like this FAQ database encourages flexibility regarding when one can join the course, provided they manage their timelines effectively with respect to assignment submission and understanding that a confirmation email or registration list isn't mandatory for participation as acceptance is assumed once you register. The slack channel remains open for support even in self-paced mode, but it’s advised first checking the FAQ document which might answer your questions already covered therein.\n",
      "\n",
      "As always with courses that allow late registrations or are designed to be flexible and student-driven (it's not clear if this course is a traditional setting based on context), each situation may require personal judgment, keeping deadlines in mind while ensuring you understand the tools and content needed prior starting out. The information provided doesn't include specific dates for expected confirmation emails or final project due dates – these would typically be set by individual courses outside of this FAQ database but knowing to stay informed through official course communication channels is essential advice that aligns with good practice, regardless if you are joining soon after the start date.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
